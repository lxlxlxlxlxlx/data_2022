{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a6890b4-4635-4145-9957-e2fb4bebb642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import json\n",
    "from tarfile import XGLTYPE\n",
    "import torch\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import csv\n",
    "from functools import reduce\n",
    "import operator\n",
    "from math import log\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n",
    "#from sklearn.metrics import f1_score, accuracy_score\n",
    "import gzip\n",
    "from utils import args\n",
    "from metrics4rec import evaluate_all\n",
    "\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd356f9d-3cb3-42b4-bc42-f2f04d57f223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2b52c45-118c-485c-9803-ee1c288689ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_candidate_items(args_):\n",
    "    print('loading candidate items...')\n",
    "    ui_cands = {}\n",
    "    ui_gt = {}\n",
    "    with gzip.open(args_.kg_test_candidates_file, 'rt') as f:\n",
    "       for line in f:\n",
    "           cells = line.split()\n",
    "           uid = int(cells[0])\n",
    "           item_ids = [int(i) for i in cells[1:]]\n",
    "           ui_cands[uid] = item_ids\n",
    "    #return ui_cands\n",
    "    #data = np.load(args_.kg_test_candidates_file)['candidates']\n",
    "    # ui_cands = {}\n",
    "    # ui_gt = {}\n",
    "    with open(args_.kg_test_triples_file, 'rt') as f:\n",
    "        for line in f:\n",
    "            line = line.split()\n",
    "            uid = int(line[0])\n",
    "            iid = int(line[1])\n",
    "            if uid not in ui_gt:\n",
    "                ui_gt[uid] = [iid]\n",
    "            else:\n",
    "                ui_gt[uid].append(iid)\n",
    "\n",
    "    return ui_cands, ui_gt\n",
    "\n",
    "# def main():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a84bb43e-37be-431d-b5ed-45f33ac2a390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading transE embedding...\n",
      "<class 'numpy.ndarray'> (169931, 100)\n",
      "<class 'numpy.ndarray'> (90, 100)\n",
      "loading candidate items...\n",
      "61254\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "print('loading transE embedding...')\n",
    "ckpt = torch.load(args.transE_embedding_file, map_location=torch.device('cpu'))\n",
    "embeds = ckpt['ent_embeddings.weight'].cpu().numpy()\n",
    "rels = ckpt['rel_embeddings.weight'].cpu().numpy()\n",
    "\n",
    "print(type(embeds), embeds.shape)\n",
    "print(type(rels), rels.shape)\n",
    "#%%\n",
    "ui_cands, gt = load_candidate_items(args)\n",
    "print(len(ui_cands))\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc8a5e1c-cc32-42f3-a5a2-ab61417ce3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "def transE_eval(embeds, rels, ui_cands):\n",
    "    ui_scores = {}\n",
    "    cnt = 0\n",
    "    for uid in ui_cands:\n",
    "        iids = ui_cands[uid]\n",
    "        u_emb = embeds[uid] + rels[0]  # user + purchase\n",
    "        i_embs = embeds[iids]\n",
    "        scores = np.expand_dims(u_emb, 0) - i_embs\n",
    "        scores = LA.norm(scores, ord=1, axis=1) * (-1)  # larger is better\n",
    "        ui_scores[uid] = dict(zip(iids, scores.tolist()))\n",
    "        cnt += 1\n",
    "        if cnt % 5000 == 0:\n",
    "            print(cnt)\n",
    "    return ui_scores\n",
    "\n",
    "def causal_eval(opti_ui, opti_path_rep):\n",
    "    vae_model = torch.load(args.vae_model_path, map_location=torch.device(device))\n",
    "    vae_model.eval()\n",
    "    model = torch.load(args.rec_model_path, map_location=torch.device(device))\n",
    "    model.eval()\n",
    "    re = []\n",
    "    with torch.no_grad():\n",
    "        rep_z = vae_model.get_z(torch.from_numpy(opti_path_rep).to(torch.device(device)))\n",
    "    X = np.concatenate([embeds[opti_ui].reshape(-1,200), rep_z], axis=-1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = model(torch.from_numpy(X).to(torch.device(device)))\n",
    "    return dict_scores(opti_ui, scores)\n",
    "\n",
    "def ui_eval(X):\n",
    "    print('cal ui score...')\n",
    "    model = torch.load(args.rec_ui_model_path, map_location=torch.device(device))\n",
    "    #print(model.device())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model(torch.from_numpy(X).to(torch.device(device)))\n",
    "    return dict_scores(ui, scores)\n",
    "\n",
    "def uip_eval(opti_ui, opti_path_rep):\n",
    "    X = np.concatenate([embeds[opti_ui].reshape(-1,200), opti_path_rep], axis=-1)\n",
    "    model = torch.load(args.rec_uip_model_path, map_location=torch.device(device))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model(torch.from_numpy(X).to(torch.device(device)))\n",
    "    return dict_scores(opti_ui, scores)\n",
    "\n",
    "def i_sbt_u_eval(X):\n",
    "    X = X[:,100:] - X[:,:100]\n",
    "    model = torch.load(args.rec_isu_model_path, map_location=torch.device(device))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model(torch.from_numpy(X).to(torch.device(device)))\n",
    "    return dict_scores(ui, scores)\n",
    "\n",
    "def i_sbt_up_eval(X):\n",
    "    X = X[:,100:] - X[:,:100] - rels[0]\n",
    "    model = torch.load(args.rec_isup_model_path, map_location=torch.device(device))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model(torch.from_numpy(X).to(torch.device(device)))\n",
    "    return dict_scores(ui, scores)\n",
    "\n",
    "def i_sbt_up_n1_eval(X):\n",
    "    X = X[:,100:] - X[:,:100] - rels[0]\n",
    "    X = LA.norm(X, ord=1, axis=1).reshape(-1,1)\n",
    "    model = torch.load(args.rec_isupn1_model_path, map_location=torch.device(device))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model(torch.from_numpy(X).to(torch.device(device)))\n",
    "    return dict_scores(ui, scores)\n",
    "\n",
    "def i_sbt_up_abs_eval(X):\n",
    "    X = X[:,100:] - X[:,:100] - rels[0]\n",
    "    X = np.abs(X)\n",
    "    model = torch.load(args.rec_isup_abs_model_path, map_location=torch.device(device))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model(torch.from_numpy(X).to(torch.device(device)))\n",
    "    return dict_scores(ui, scores)\n",
    "\n",
    "def p_eval():\n",
    "    pass\n",
    "\n",
    "def dict_scores(ui, scores):\n",
    "    print('dicting score...')\n",
    "    ui_scores = {}\n",
    "    for i, u in enumerate(ui[::1000][:,0].flatten()):\n",
    "        ui_scores[u] = dict(zip(ui[i*1000:(i+1)*1000,1].tolist(), scores[i*1000:(i+1)*1000].tolist()))\n",
    "    return ui_scores\n",
    "\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92bac968-d434-4298-befa-2466923730c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map embedding to ui...\n"
     ]
    }
   ],
   "source": [
    "print('map embedding to ui...')\n",
    "ui = np.zeros((len(ui_cands)*1000, 2), dtype=np.int)\n",
    "for i, u in enumerate(ui_cands):\n",
    "    ui[1000*i:1000*(i+1), 0] = u\n",
    "    ui[1000*i:1000*(i+1), 1] = ui_cands[u]\n",
    "ui_emb = embeds[ui].reshape(-1,200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f91a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#args.inter_data_dir = f\"./{args.save_dir}/{args.mode}/\"\n",
    "opti_paths = np.load(args.test_data_dir+'opti_paths.npy')\n",
    "# opti_path_rep = np.load(args.test_data_dir+'opti_path_rep.npy')\n",
    "\n",
    "nodes_emb = embeds[opti_paths[:,:,0]]\n",
    "edges_emb = rels[opti_paths[:,1:,1]]\n",
    "nodes_emb = np.sum(nodes_emb, axis=-2)\n",
    "edges_emb = np.sum(edges_emb, axis=-2)\n",
    "opti_path_rep = (nodes_emb+edges_emb)/7\n",
    "\n",
    "# opti_paths_emb = np.concatenate([nodes_emb, edges_emb],axis=1)\n",
    "\n",
    "# def represent_avg(v):\n",
    "#     return np.average(v, axis=-2)\n",
    "\n",
    "# opti_path_rep = represent_avg(opti_paths_emb)\n",
    "\n",
    "#%%\n",
    "opti_ui = opti_paths[:,[0,3],0]\n",
    "opti_ui_emb = embeds[opti_ui].reshape(-1,200)\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfeaf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dicting score...\n",
      "evaluating scores...\n",
      "\n",
      "NDCG@10\tRec@10\tHits@10\tPrec@10\tMAP@10\tMRR@10\n",
      "0.2335\t0.2255\t0.3816\t0.0474\t0.1838\t0.1918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('\\nNDCG@10\\tRec@10\\tHits@10\\tPrec@10\\tMAP@10\\tMRR@10\\n0.2335\\t0.2255\\t0.3816\\t0.0474\\t0.1838\\t0.1918',\n",
       " {'ndcg': 0.23351364252632265,\n",
       "  'map': 0.18380900167950323,\n",
       "  'recall': 0.22550268065021972,\n",
       "  'precision': 0.04736180494333165,\n",
       "  'mrr': 0.19176290268831164,\n",
       "  'hit': 0.3815914062755085})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui_scores = i_sbt_up_abs_eval(ui_emb)\n",
    "print('evaluating scores...')\n",
    "evaluate_all(ui_scores, gt, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f4bee79-9d2c-4866-8121-7789f387368d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dicting score...\n",
      "evaluating scores...\n",
      "\n",
      "NDCG@10\tRec@10\tHits@10\tPrec@10\tMAP@10\tMRR@10\n",
      "0.1264\t0.1167\t0.2113\t0.0244\t0.0988\t0.1016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('\\nNDCG@10\\tRec@10\\tHits@10\\tPrec@10\\tMAP@10\\tMRR@10\\n0.1264\\t0.1167\\t0.2113\\t0.0244\\t0.0988\\t0.1016',\n",
       " {'ndcg': 0.1263728569449435,\n",
       "  'map': 0.09876426444831023,\n",
       "  'recall': 0.1166635966655034,\n",
       "  'precision': 0.0244191670697309,\n",
       "  'mrr': 0.10161012879336011,\n",
       "  'hit': 0.21126807545407542})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal_scores = causal_eval(opti_ui, opti_path_rep)\n",
    "print('evaluating scores...')\n",
    "evaluate_all(causal_scores, gt, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b578bd5b-96e4-493c-947d-ba992881d3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "evaluating scores...\n",
      "\n",
      "NDCG@10\tRec@10\tHits@10\tPrec@10\tMAP@10\tMRR@10\n",
      "0.2703\t0.2598\t0.4341\t0.0540\t0.2146\t0.2249\n",
      "dicting score...\n",
      "evaluating scores...\n",
      "\n",
      "NDCG@10\tRec@10\tHits@10\tPrec@10\tMAP@10\tMRR@10\n",
      "0.1267\t0.1165\t0.2115\t0.0245\t0.0992\t0.1021\n",
      "dicting score...\n",
      "evaluating scores...\n",
      "\n",
      "NDCG@10\tRec@10\tHits@10\tPrec@10\tMAP@10\tMRR@10\n",
      "0.1217\t0.1121\t0.2030\t0.0236\t0.0952\t0.0981\n",
      "cal ui score...\n",
      "dicting score...\n",
      "evaluating scores...\n",
      "\n",
      "NDCG@10\tRec@10\tHits@10\tPrec@10\tMAP@10\tMRR@10\n",
      "0.2443\t0.2382\t0.4005\t0.0497\t0.1919\t0.2002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('\\nNDCG@10\\tRec@10\\tHits@10\\tPrec@10\\tMAP@10\\tMRR@10\\n0.2443\\t0.2382\\t0.4005\\t0.0497\\t0.1919\\t0.2002',\n",
       " {'ndcg': 0.24429426140275118,\n",
       "  'map': 0.19185834654034203,\n",
       "  'recall': 0.23821289226257425,\n",
       "  'precision': 0.04971430437193862,\n",
       "  'mrr': 0.20016037177487858,\n",
       "  'hit': 0.40047996865510826})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "ui_scores = transE_eval(embeds, rels, ui_cands)\n",
    "print('evaluating scores...')\n",
    "evaluate_all(ui_scores, gt, 10)\n",
    "#%%\n",
    "causal_scores = causal_eval(opti_ui, opti_path_rep)\n",
    "print('evaluating scores...')\n",
    "evaluate_all(causal_scores, gt, 10)\n",
    "#%%\n",
    "uip_scores = uip_eval(opti_ui, opti_path_rep)\n",
    "print('evaluating scores...')\n",
    "evaluate_all(uip_scores, gt, 10)\n",
    "#%%\n",
    "#uip_emb\n",
    "ui_scores = ui_eval(ui_emb)\n",
    "print('evaluating scores...')\n",
    "evaluate_all(ui_scores, gt, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf38bf50-2738-41d6-a4ff-18c656f85a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dicting score...\n",
      "evaluating scores...\n",
      "\n",
      "NDCG@10\tRec@10\tHits@10\tPrec@10\tMAP@10\tMRR@10\n",
      "0.2357\t0.2293\t0.3871\t0.0480\t0.1849\t0.1932\n",
      "dicting score...\n",
      "evaluating scores...\n",
      "\n",
      "NDCG@10\tRec@10\tHits@10\tPrec@10\tMAP@10\tMRR@10\n",
      "0.2359\t0.2277\t0.3852\t0.0476\t0.1859\t0.1940\n",
      "dicting score...\n",
      "evaluating scores...\n",
      "\n",
      "NDCG@10\tRec@10\tHits@10\tPrec@10\tMAP@10\tMRR@10\n",
      "0.2703\t0.2598\t0.4341\t0.0540\t0.2146\t0.2249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('\\nNDCG@10\\tRec@10\\tHits@10\\tPrec@10\\tMAP@10\\tMRR@10\\n0.2703\\t0.2598\\t0.4341\\t0.0540\\t0.2146\\t0.2249',\n",
       " {'ndcg': 0.27026332769750877,\n",
       "  'map': 0.2146468781728277,\n",
       "  'recall': 0.2598469854108456,\n",
       "  'precision': 0.05397525059585517,\n",
       "  'mrr': 0.22489408531013977,\n",
       "  'hit': 0.43411042544160383})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "ui_scores = i_sbt_u_eval(ui_emb)\n",
    "print('evaluating scores...')\n",
    "evaluate_all(ui_scores, gt, 10)\n",
    "#%%\n",
    "ui_scores = i_sbt_up_eval(ui_emb)\n",
    "print('evaluating scores...')\n",
    "evaluate_all(ui_scores, gt, 10)\n",
    "#%%\n",
    "ui_scores = i_sbt_up_n1_eval(ui_emb)\n",
    "print('evaluating scores...')\n",
    "evaluate_all(ui_scores, gt, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3302fb-0dfa-4198-a8e7-c10e5ba0e136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m81"
  },
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python env3.7",
   "language": "python",
   "name": "env3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
